// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v6.32.1
// source: backend.proto

package inferencev1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	structpb "google.golang.org/protobuf/types/known/structpb"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Request for inference
type InferenceRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Provider      string                 `protobuf:"bytes,1,opt,name=provider,proto3" json:"provider,omitempty"`
	ModelId       string                 `protobuf:"bytes,2,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"` // Logical model ID, e.g. "llama2-7b"
	Input         []byte                 `protobuf:"bytes,3,opt,name=input,proto3" json:"input,omitempty"`                    // Raw input (text, audio, image, etc.)
	Parameters    *structpb.Struct       `protobuf:"bytes,4,opt,name=parameters,proto3" json:"parameters,omitempty"`          // Backend-specific inference params
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceRequest) Reset() {
	*x = InferenceRequest{}
	mi := &file_backend_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceRequest) ProtoMessage() {}

func (x *InferenceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_backend_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceRequest.ProtoReflect.Descriptor instead.
func (*InferenceRequest) Descriptor() ([]byte, []int) {
	return file_backend_proto_rawDescGZIP(), []int{0}
}

func (x *InferenceRequest) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *InferenceRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *InferenceRequest) GetInput() []byte {
	if x != nil {
		return x.Input
	}
	return nil
}

func (x *InferenceRequest) GetParameters() *structpb.Struct {
	if x != nil {
		return x.Parameters
	}
	return nil
}

// Response for synchronous inference
type InferenceResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Output        []byte                 `protobuf:"bytes,1,opt,name=output,proto3" json:"output,omitempty"`     // Raw output (text, audio, image, etc.)
	Metadata      *InferenceMetadata     `protobuf:"bytes,2,opt,name=metadata,proto3" json:"metadata,omitempty"` // Metadata describing inference results
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceResponse) Reset() {
	*x = InferenceResponse{}
	mi := &file_backend_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceResponse) ProtoMessage() {}

func (x *InferenceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_backend_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceResponse.ProtoReflect.Descriptor instead.
func (*InferenceResponse) Descriptor() ([]byte, []int) {
	return file_backend_proto_rawDescGZIP(), []int{1}
}

func (x *InferenceResponse) GetOutput() []byte {
	if x != nil {
		return x.Output
	}
	return nil
}

func (x *InferenceResponse) GetMetadata() *InferenceMetadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// Streaming response chunk
type StreamChunk struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Data          []byte                 `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`         // Partial output (UTF-8 text or bytes)
	Done          bool                   `protobuf:"varint,2,opt,name=done,proto3" json:"done,omitempty"`        // Indicates last chunk
	Error         string                 `protobuf:"bytes,3,opt,name=error,proto3" json:"error,omitempty"`       // Optional error message
	Metadata      *InferenceMetadata     `protobuf:"bytes,4,opt,name=metadata,proto3" json:"metadata,omitempty"` // Optional metadata
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamChunk) Reset() {
	*x = StreamChunk{}
	mi := &file_backend_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamChunk) ProtoMessage() {}

func (x *StreamChunk) ProtoReflect() protoreflect.Message {
	mi := &file_backend_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamChunk.ProtoReflect.Descriptor instead.
func (*StreamChunk) Descriptor() ([]byte, []int) {
	return file_backend_proto_rawDescGZIP(), []int{2}
}

func (x *StreamChunk) GetData() []byte {
	if x != nil {
		return x.Data
	}
	return nil
}

func (x *StreamChunk) GetDone() bool {
	if x != nil {
		return x.Done
	}
	return false
}

func (x *StreamChunk) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

func (x *StreamChunk) GetMetadata() *InferenceMetadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// Metadata describing inference results
type InferenceMetadata struct {
	state           protoimpl.MessageState     `protogen:"open.v1"`
	Provider        string                     `protobuf:"bytes,1,opt,name=provider,proto3" json:"provider,omitempty"`                                                                                                                // Backend provider
	Model           string                     `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`                                                                                                                      // Model file path or ID
	Timestamp       *timestamppb.Timestamp     `protobuf:"bytes,3,opt,name=timestamp,proto3" json:"timestamp,omitempty"`                                                                                                              // Time of inference
	OutputSizeBytes int64                      `protobuf:"varint,4,opt,name=output_size_bytes,json=outputSizeBytes,proto3" json:"output_size_bytes,omitempty"`                                                                        // Size of output in bytes
	DurationSeconds float64                    `protobuf:"fixed64,5,opt,name=duration_seconds,json=durationSeconds,proto3" json:"duration_seconds,omitempty"`                                                                         // Total processing duration
	BackendSpecific map[string]*structpb.Value `protobuf:"bytes,6,rep,name=backend_specific,json=backendSpecific,proto3" json:"backend_specific,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // Diagnostic data
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *InferenceMetadata) Reset() {
	*x = InferenceMetadata{}
	mi := &file_backend_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceMetadata) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceMetadata) ProtoMessage() {}

func (x *InferenceMetadata) ProtoReflect() protoreflect.Message {
	mi := &file_backend_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceMetadata.ProtoReflect.Descriptor instead.
func (*InferenceMetadata) Descriptor() ([]byte, []int) {
	return file_backend_proto_rawDescGZIP(), []int{3}
}

func (x *InferenceMetadata) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *InferenceMetadata) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *InferenceMetadata) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

func (x *InferenceMetadata) GetOutputSizeBytes() int64 {
	if x != nil {
		return x.OutputSizeBytes
	}
	return 0
}

func (x *InferenceMetadata) GetDurationSeconds() float64 {
	if x != nil {
		return x.DurationSeconds
	}
	return 0
}

func (x *InferenceMetadata) GetBackendSpecific() map[string]*structpb.Value {
	if x != nil {
		return x.BackendSpecific
	}
	return nil
}

var File_backend_proto protoreflect.FileDescriptor

const file_backend_proto_rawDesc = "" +
	"\n" +
	"\rbackend.proto\x12\finference.v1\x1a\x1cgoogle/protobuf/struct.proto\x1a\x1fgoogle/protobuf/timestamp.proto\"\x98\x01\n" +
	"\x10InferenceRequest\x12\x1a\n" +
	"\bprovider\x18\x01 \x01(\tR\bprovider\x12\x19\n" +
	"\bmodel_id\x18\x02 \x01(\tR\amodelId\x12\x14\n" +
	"\x05input\x18\x03 \x01(\fR\x05input\x127\n" +
	"\n" +
	"parameters\x18\x04 \x01(\v2\x17.google.protobuf.StructR\n" +
	"parameters\"h\n" +
	"\x11InferenceResponse\x12\x16\n" +
	"\x06output\x18\x01 \x01(\fR\x06output\x12;\n" +
	"\bmetadata\x18\x02 \x01(\v2\x1f.inference.v1.InferenceMetadataR\bmetadata\"\x88\x01\n" +
	"\vStreamChunk\x12\x12\n" +
	"\x04data\x18\x01 \x01(\fR\x04data\x12\x12\n" +
	"\x04done\x18\x02 \x01(\bR\x04done\x12\x14\n" +
	"\x05error\x18\x03 \x01(\tR\x05error\x12;\n" +
	"\bmetadata\x18\x04 \x01(\v2\x1f.inference.v1.InferenceMetadataR\bmetadata\"\x93\x03\n" +
	"\x11InferenceMetadata\x12\x1a\n" +
	"\bprovider\x18\x01 \x01(\tR\bprovider\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x128\n" +
	"\ttimestamp\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\x12*\n" +
	"\x11output_size_bytes\x18\x04 \x01(\x03R\x0foutputSizeBytes\x12)\n" +
	"\x10duration_seconds\x18\x05 \x01(\x01R\x0fdurationSeconds\x12_\n" +
	"\x10backend_specific\x18\x06 \x03(\v24.inference.v1.InferenceMetadata.BackendSpecificEntryR\x0fbackendSpecific\x1aZ\n" +
	"\x14BackendSpecificEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12,\n" +
	"\x05value\x18\x02 \x01(\v2\x16.google.protobuf.ValueR\x05value:\x028\x012\xaa\x01\n" +
	"\x10InferenceService\x12H\n" +
	"\x05Infer\x12\x1e.inference.v1.InferenceRequest\x1a\x1f.inference.v1.InferenceResponse\x12L\n" +
	"\vInferStream\x12\x1e.inference.v1.InferenceRequest\x1a\x19.inference.v1.StreamChunk(\x010\x01B\x1aZ\x18inference/v1;inferencev1b\x06proto3"

var (
	file_backend_proto_rawDescOnce sync.Once
	file_backend_proto_rawDescData []byte
)

func file_backend_proto_rawDescGZIP() []byte {
	file_backend_proto_rawDescOnce.Do(func() {
		file_backend_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_backend_proto_rawDesc), len(file_backend_proto_rawDesc)))
	})
	return file_backend_proto_rawDescData
}

var file_backend_proto_msgTypes = make([]protoimpl.MessageInfo, 5)
var file_backend_proto_goTypes = []any{
	(*InferenceRequest)(nil),      // 0: inference.v1.InferenceRequest
	(*InferenceResponse)(nil),     // 1: inference.v1.InferenceResponse
	(*StreamChunk)(nil),           // 2: inference.v1.StreamChunk
	(*InferenceMetadata)(nil),     // 3: inference.v1.InferenceMetadata
	nil,                           // 4: inference.v1.InferenceMetadata.BackendSpecificEntry
	(*structpb.Struct)(nil),       // 5: google.protobuf.Struct
	(*timestamppb.Timestamp)(nil), // 6: google.protobuf.Timestamp
	(*structpb.Value)(nil),        // 7: google.protobuf.Value
}
var file_backend_proto_depIdxs = []int32{
	5, // 0: inference.v1.InferenceRequest.parameters:type_name -> google.protobuf.Struct
	3, // 1: inference.v1.InferenceResponse.metadata:type_name -> inference.v1.InferenceMetadata
	3, // 2: inference.v1.StreamChunk.metadata:type_name -> inference.v1.InferenceMetadata
	6, // 3: inference.v1.InferenceMetadata.timestamp:type_name -> google.protobuf.Timestamp
	4, // 4: inference.v1.InferenceMetadata.backend_specific:type_name -> inference.v1.InferenceMetadata.BackendSpecificEntry
	7, // 5: inference.v1.InferenceMetadata.BackendSpecificEntry.value:type_name -> google.protobuf.Value
	0, // 6: inference.v1.InferenceService.Infer:input_type -> inference.v1.InferenceRequest
	0, // 7: inference.v1.InferenceService.InferStream:input_type -> inference.v1.InferenceRequest
	1, // 8: inference.v1.InferenceService.Infer:output_type -> inference.v1.InferenceResponse
	2, // 9: inference.v1.InferenceService.InferStream:output_type -> inference.v1.StreamChunk
	8, // [8:10] is the sub-list for method output_type
	6, // [6:8] is the sub-list for method input_type
	6, // [6:6] is the sub-list for extension type_name
	6, // [6:6] is the sub-list for extension extendee
	0, // [0:6] is the sub-list for field type_name
}

func init() { file_backend_proto_init() }
func file_backend_proto_init() {
	if File_backend_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_backend_proto_rawDesc), len(file_backend_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   5,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_backend_proto_goTypes,
		DependencyIndexes: file_backend_proto_depIdxs,
		MessageInfos:      file_backend_proto_msgTypes,
	}.Build()
	File_backend_proto = out.File
	file_backend_proto_goTypes = nil
	file_backend_proto_depIdxs = nil
}
